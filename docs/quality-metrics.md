# Quality Metrics Guide

This document describes the key performance indicators (KPIs) used to track code and application quality, as well as the tools used to gather them.

## KPIs

- **Test coverage** – Percentage of lines covered by automated tests.
- **Build time** – Duration of CI builds for both Python and frontend workflows.
- **Core Web Vitals** – Metrics such as Largest Contentful Paint (LCP) and Cumulative Layout Shift (CLS) measured on the built dashboard.
- **Bug rate** – Number of open issues labeled `bug`.
- **Security vulnerabilities** – High or critical issues detected in dependencies.

## Collection Methods

| KPI                    | Tool/Source              | Notes |
| ---------------------- | ------------------------ | ----- |
| Coverage               | **Codecov**              | Coverage reports generated by `pytest --cov` are uploaded and tracked on [Codecov](https://about.codecov.io/). |
| Build time             | **GitHub Actions**       | CI logs expose the total runtime for each job; historical data is visible in the Actions tab. |
| Core Web Vitals        | **Lighthouse‑CI**        | `@lhci/cli` runs against the deployed dashboard and stores JSON reports. |
| Bug rate               | **GitHub Issues**        | Count of open issues with the label `bug`. |
| Vulnerabilities        | **Snyk / CodeQL**        | Weekly scans report dependency and code risks. |

Metrics collected by the workflow are posted to a Slack channel (or any compatible webhook) for visibility.
